#!/bin/bash

# Define variables
ENDPOINT_URL="https://your-s3-compatible-service-endpoint"
BUCKET_NAME="your-bucket-name"
ACCESS_KEY="your-access-key-id"
SECRET_KEY="your-secret-access-key"
REGION="your-region-name"
EMAIL="your-email@example.com"
DIRECTORY_PATH="/path/to/your/specified/folder"

# Export AWS credentials (optional if not already configured globally)
export AWS_ACCESS_KEY_ID=${ACCESS_KEY}
export AWS_SECRET_ACCESS_KEY=${SECRET_KEY}
export AWS_DEFAULT_REGION=${REGION}

# Find .bak files in the specified directory
FILES=($(find "${DIRECTORY_PATH}" -type f -name "*.bak"))

# Check if files are found
if [ ${#FILES[@]} -eq 0 ]; then
    echo "No .bak files found in ${DIRECTORY_PATH}."
    exit 0
fi

# Flag to track upload success
ALL_UPLOADS_SUCCESSFUL=1

# Loop through files and upload each one
for FILE_PATH in "${FILES[@]}"; do
    FILE_KEY=$(basename "${FILE_PATH}")

    # Attempt to upload the file
    if aws s3 cp "${FILE_PATH}" s3://"${BUCKET_NAME}"/"${FILE_KEY}" --endpoint-url "${ENDPOINT_URL}"; then
        echo "File ${FILE_PATH} uploaded successfully."
    else
        echo "Failed to upload ${FILE_PATH}."
        ALL_UPLOADS_SUCCESSFUL=0
        break # Exit the loop on the first failure
    fi
done

# Check if all uploads were successful
if [ ${ALL_UPLOADS_SUCCESSFUL} -eq 1 ]; then
    echo "All files uploaded successfully. Deleting local files."

    # Assuming all files have been uploaded successfully
    
    # List and sort only .bak files by date, keeping the 48 most recent
    MOST_RECENT_FILES=$(aws s3api list-objects-v2 --bucket "${BUCKET_NAME}" --query "Contents[?ends_with(Key, '.bak')].[Key]" --output text | sort -k1,1 | tail -n 48)
    
    # Convert sorted file list to an array
    readarray -t SORTED_FILES <<< "$MOST_RECENT_FILES"
    
    # List all .bak files
    ALL_FILES=$(aws s3api list-objects-v2 --bucket "${BUCKET_NAME}" --query "Contents[?ends_with(Key, '.bak')].[Key]" --output text)
    
    # Convert all file list to an array
    readarray -t ALL_FILES_ARR <<< "$ALL_FILES"
    
    # Loop through all .bak files and delete if not in the 48 most recent
    for FILE_KEY in "${ALL_FILES_ARR[@]}"; do
        if [[ ! " ${SORTED_FILES[*]} " =~ " ${FILE_KEY} " ]]; then
            echo "Deleting old file: ${FILE_KEY}"
            aws s3api delete-object --bucket "${BUCKET_NAME}" --key "${FILE_KEY}"
        fi
    done
    
    echo "Old files deleted. Only the 48 most recent .bak files are kept in the bucket."

    # Delete the files
    for FILE_PATH in "${FILES[@]}"; do
        rm "${FILE_PATH}"
    done
else
    echo "Upload failed. Sending an email."
    # Send an email notification
    echo "At least one file failed to upload. Please check the logs." | mail -s "Upload to S3 failed" "${EMAIL}"
fi
